{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas workbook\n",
    "\n",
    "In this notebook we will review some Pandas tricks. Examples will use the iris dataset from R.A. Fisher, 1936 as provided by the [UCI ML repo](https://archive.ics.uci.edu/dataset/53/iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "iris = pd.read_csv('iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's filter for the species being versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris['species'] == 'versicolor'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris['species'].isin(['versicolor', 'setosa'])].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: How many observations have sepal length in the upper 50% quantile and petal width greater than 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.quantile(iris['sepal_length'], 0.5)\n",
    "len(iris[(iris['sepal_length'] > thresh) & (iris['petal_width']>2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting\n",
    "\n",
    "We may want to select only a subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[['sepal_length', 'species']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns except sepal length and species\n",
    "iris[iris.columns.difference(['sepal_length', 'species'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: How would you select only the columns containing the word \"length\", without explicitly writing them out? (in a bigger dataset where there may be dozens of columns containing \"length\", you wouldn't want to type them all out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.columns.str.contains('length'))\n",
    "print(iris.columns[iris.columns.str.contains('length')])\n",
    "iris[iris.columns[iris.columns.str.contains('length')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select columns of only certain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only numeric columns\n",
    "iris.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a new dataframe with a new column `sepal_sum`, which holds the sum of `sepal_length` and `sepal_width` for `versicolor` flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_vc = iris[iris['species'] == 'versicolor']\n",
    "iris_vc['sepal_sum'] = iris_vc['sepal_length'] + iris_vc['sepal_width']\n",
    "iris_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply every column containing \"sepal\" by 2\n",
    "iris_new = iris.copy()\n",
    "iris_new.loc[:, iris_new.columns.str.contains('sepal')] *= 2\n",
    "iris_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('species').apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: For each species, randomly select half of the observations and compute the 0.25 quantile for each feature (i.e., sepal_length, sepal_width, petal_length, and petal_width). Hint: see `DataFrame.sample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('species').sample(25).groupby('species').quantile(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values('petal_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values(['petal_length', 'sepal_width'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: For each species, only keep the observations with the largest 10 sepal lengths. Then, sort the rows in order of decreasing sepal length. Hint: can you do this using an `apply` with a `group_by`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('species').apply(lambda x: x.sort_values('sepal_length', ascending=False).head(10), include_groups=False)\n",
    "iris.groupby('species').apply(lambda x: x.nlargest(10, 'sepal_length'), include_groups=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merges (joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a couple dataframes to play around with merges (aka joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "lowercase_data = pd.DataFrame(dict(id = range(2,7), lower = list(string.ascii_lowercase[1:6])))\n",
    "lowercase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_data = pd.DataFrame(dict(id = range(1,6), upper = list(string.ascii_uppercase[0:5])))\n",
    "uppercase_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these to demonstrate all four kinds of joins. In each case, the DataFrames are automatically joined on the common column `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lat's make a DataFrame which is rather messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_messy = pd.concat((iris, iris.sample(n=50, replace=True))).sample(frac=1).reset_index(drop=True)\n",
    "iris_messy.loc[np.random.sample(iris_messy.shape[0]) < 0.1,'species'] = pd.NA\n",
    "iris_messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: clean up `iris_messy` to remove duplicate rows and rows with an NA value in `species`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up iris_messy\n",
    "iris_messy = iris_messy.drop_duplicates()\n",
    "iris_messy = iris_messy.dropna(subset=['species'])\n",
    "iris_messy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
